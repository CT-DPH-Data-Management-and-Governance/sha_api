---
title: quick eda on vars
---

```{python}

from dataops.models import CensusAPIEndpoint as ce
import polars as pl

testcase1 = ce.from_url(
    "https://api.census.gov/data/2023/acs/acs5/subject?get=group(S0101)&ucgid=0400000US09"
)

testcase2 = ce.from_url(
    "https://api.census.gov/data/2023/acs/acs1?get=group(B19013I)&ucgid=0400000US09"
)

testcase3 = ce.from_url(
    "https://api.census.gov/data/2023/acs/acs1?get=group(B25088)&ucgid=0400000US09"
)


data2_raw = testcase2.fetch_data_to_polars()
data2_raw

# >>> data2_raw = testcase2.fetch_data_to_polars()
# >>> data2_raw
# shape: (4, 6)
# headers	records	geo_id	ucgid	geo_name	date_pulled
# str	str	str	str	str	datetime[μs]
# "B19013I_001E"	"61081"	"0400000US09"	"0400000US09"	"Connecticut"	2025-07-11 13:07:03.642779
# "B19013I_001EA"	"61081"	"0400000US09"	"0400000US09"	"Connecticut"	2025-07-11 13:07:03.642779
# "B19013I_001M"	"3265"	"0400000US09"	"0400000US09"	"Connecticut"	2025-07-11 13:07:03.642779
# "B19013I_001MA"	"3265"	"0400000US09"	"0400000US09"	"Connecticut"	2025-07-11 13:07:03.642779


data2_tidy = testcase2.fetch_tidy_data()
data2_tidy

data3_raw = testcase3.fetch_data_to_polars()
data3_raw

data3_tidy = testcase3.fetch_tidy_data()
data3_tidy

```

headers in raw and variable_id in tidy one

- E estimate
- M margin of error
- PE percent ""
- PM percent ""
- EA
- MA
- PMA
- SS  statistical significance

## parse the var ids

example: "B19013I_001E"

base table: B - detail table

table id: B19013I -  'median household income in the past 12 months 
(in 2023 inflation-adjusted dollars) (hispanic or latino householder)'

line number: 001 - line one
value type: E - estimate

## b tables

```{python}
# test parse

df = data3_tidy


vars = (
    df.lazy()
    .select(["row_id", "variable_id", "variable_name", "value", "value_type"])
    .with_columns(
        pl.col("variable_id")
        .str.split_exact(
            by="_", n=1
        )  # this will totally break with the 3 part subject table names
        .struct.rename_fields(["table_id", "line_id"])
        .alias("parts")
    )
    .unnest("parts")
    .with_columns(
        pl.col("table_id").str.slice(0, 1).alias("table_type"),
        pl.col("table_id").str.slice(1, 2).alias("table_subject_id"),
        pl.col("table_id").str.slice(3, 3).alias("subject_table_number"),
        pl.col("table_id").str.slice(6).alias("table_id_suffix"),
    )
    .with_columns(
        pl.col("line_id").str.slice(0, 3).alias("line_number").str.to_integer(),
        pl.col("line_id").str.slice(3).alias("line_suffix"),
    )
)


vars.head().collect()


```



```{python}
try_pivot = vars.select(
    [
        #    "row_id",
        "variable_id",
        "variable_name",
        "value",
        "line_number",
        "line_suffix",
    ]
).collect()

try_pivot.head()


yes= try_pivot.pivot("line_suffix", index=["line_number", "variable_name"], values="value")
yes
```



```{python}
print("so from this:")
print(vars.head().collect())
print("to this:")
print(yes)
```



## s tables


```{python}


df = testcase1.fetch_tidy_data().lazy()

# do when then otherwise for s vs b etc..

subj_vars = (
    df.select(["row_id", "variable_id", "variable_name", "value", "value_type"])
    .with_columns(pl.col("variable_id").str.slice(0, 1).alias("table_type"))
    .with_columns(
        pl.col("variable_id")
        .str.split_exact(
            by="_", n=2
        )  # this will totally break with the 3 part subject table names
        .struct.rename_fields(
            [
                "table_id",
                "column_id",
                "line_id",
            ]
        )
        .alias("parts")
    )
    .unnest("parts")
    .with_columns(
        pl.col("table_id").str.slice(0, 1).alias("table_type"),
        pl.col("table_id").str.slice(1, 2).alias("table_subject_id"),
        pl.col("table_id").str.slice(3, 3).alias("subject_table_number"),
        pl.col("table_id").str.slice(6).alias("table_id_suffix"),
        pl.col("column_id").str.slice(-2).str.to_integer().alias("column_number"),
    )
    .with_columns(
        pl.col("line_id").str.slice(0, 3).alias("line_number").str.to_integer(),
        pl.col("line_id").str.slice(3).alias("line_suffix"),
    )
)


subj_vars.head().collect()

```


```{python}
subj_try_pivot = subj_vars.select(
    [
        #    "row_id",
        "variable_id",
        "variable_name",
        "value",
        "column_number",
        "line_number",
        "line_suffix",
    ]
).collect()

subj_try_pivot.head()


yes = subj_try_pivot.pivot(
    "column_number",
    index=["line_number", "variable_name", "line_suffix"],
    values="value",
)
yes

```


yikes - I can probably do a little better in that pivot etc...
but I checked the "human-readable" landing page and there is
so much nesting. their 6 columns is really 12, and maybe 3 mini
tables tack horizontally. I don't think we're getting this in a clean
standard, easily pivotable format.

goal here is to do a better scrape of meta data out of the vars themeselves etc...
for subj tables.